{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pycaret.anomaly import setup, compare_models, save_model, load_model\n",
    "import numpy as np\n",
    "\n",
    "# Load and preprocess the packet data\n",
    "df = pd.read_csv(\"packet_data.csv\")\n",
    "df['Time'] = pd.to_numeric(df['Time'])  # Convert Time column to numeric if it's not already\n",
    "\n",
    "# Define feature engineering functions\n",
    "def feature_extraction(df):\n",
    "    features = []\n",
    "    for destination in df['Destination'].unique():\n",
    "        dest_df = df[df['Destination'] == destination]\n",
    "        \n",
    "        # Extract packet frequency feature\n",
    "        packet_count = len(dest_df)\n",
    "        \n",
    "        # Unique sources targeting the destination\n",
    "        unique_sources = dest_df['Source'].nunique()\n",
    "        \n",
    "        # Average packet length to the destination\n",
    "        avg_length = dest_df['Length'].mean()\n",
    "        \n",
    "        features.append([destination, packet_count, unique_sources, avg_length])\n",
    "        \n",
    "    # Create a DataFrame with extracted features\n",
    "    feature_df = pd.DataFrame(features, columns=['Destination', 'Packet_Count', 'Unique_Sources', 'Avg_Length'])\n",
    "    return feature_df\n",
    "\n",
    "# Extract features for training\n",
    "feature_df = feature_extraction(df)\n",
    "\n",
    "# PyCaret setup\n",
    "from pycaret.anomaly import setup, create_model, assign_model, tune_model\n",
    "\n",
    "# Setup PyCaret for anomaly detection\n",
    "exp = setup(data=feature_df[['Packet_Count', 'Unique_Sources', 'Avg_Length']], silent=True, session_id=123)\n",
    "\n",
    "# Compare models\n",
    "best_model = compare_models()\n",
    "\n",
    "# Display the best model\n",
    "print(\"Best model:\", best_model)\n",
    "\n",
    "# Assign labels to data based on best model\n",
    "predictions = assign_model(best_model)\n",
    "feature_df['Anomaly_Label'] = predictions['Anomaly'].apply(lambda x: 'DDoS' if x == -1 else 'Normal')\n",
    "\n",
    "# Save the best model for real-time usage\n",
    "save_model(best_model, 'best_ddos_model')\n",
    "\n",
    "# Real-time detection simulation\n",
    "def real_time_detection(new_packets_df, model_path='best_ddos_model'):\n",
    "    # Extract features from new data in real-time\n",
    "    new_features = feature_extraction(new_packets_df)\n",
    "    \n",
    "    # Load the best saved model\n",
    "    best_model = load_model(model_path)\n",
    "    \n",
    "    # Predict anomalies in real-time\n",
    "    new_predictions = assign_model(best_model, data=new_features[['Packet_Count', 'Unique_Sources', 'Avg_Length']])\n",
    "    new_features['Anomaly_Label'] = new_predictions['Anomaly'].apply(lambda x: 'DDoS' if x == -1 else 'Normal')\n",
    "    \n",
    "    # Display real-time alerts\n",
    "    for index, row in new_features.iterrows():\n",
    "        if row['Anomaly_Label'] == 'DDoS':\n",
    "            print(f\"Real-time Alert: Potential DDoS attack detected on destination {row['Destination']}\")\n",
    "    return new_features\n",
    "\n",
    "# Simulate real-time detection with new packet data\n",
    "new_packet_data = pd.read_csv(\"ddos_file.csv\")\n",
    "real_time_detection(new_packet_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
